{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic kernel - Plugins example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Annotated\n",
    "import dotenv\n",
    "import os\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.open_ai_prompt_execution_settings import (\n",
    "    OpenAIChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.core_plugins.time_plugin import TimePlugin\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.kernel import Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv(\"..\\\\common\\\\credentials.env\", verbose=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "aoai_api_type = os.environ[\"OPENAI_API_TYPE\"]\n",
    "deployment_name = \"gpt-4o\" # #use latest model like 4o or similar. GPT 3.5 turbo or older models doesnt seem to work as function calling/parallel tools calls is not supported in those models\n",
    "aoai_api_version = \"2024-08-01-preview\" #Using latest version as of this date.\n",
    "# Note:  Older versions of APIs than Aug 2024 and  old models doesn't work with function calling/parallel tools calls throwing error \n",
    "# as Unrecognized request argument supplied: parallel_tool_calls', 'type': 'invalid_request_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Weather and Time Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherPlugin:\n",
    "    \"\"\"A sample plugin that provides weather information for cities.\"\"\"\n",
    "\n",
    "    @kernel_function(name=\"get_weather_for_city\", description=\"Get the weather for a city\")\n",
    "    def get_weather_for_city(self, city: Annotated[str, \"The input city\"]) -> Annotated[str, \"The output is a string\"]:\n",
    "        if city == \"Boston\":\n",
    "            return \"61 and rainy\"\n",
    "        if city == \"London\":\n",
    "            return \"55 and cloudy\"\n",
    "        if city == \"Miami\":\n",
    "            return \"80 and sunny\"\n",
    "        if city == \"Paris\":\n",
    "            return \"60 and rainy\"\n",
    "        if city == \"Tokyo\":\n",
    "            return \"50 and sunny\"\n",
    "        if city == \"Sydney\":\n",
    "            return \"75 and sunny\"\n",
    "        if city == \"Tel Aviv\":\n",
    "            return \"80 and sunny\"\n",
    "        return \"31 and snowing\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use above WeatherPlugin to demonstrate the Plugin feature of SK. For getting current time we will use SK's readymade plugin called as TimePlugin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Use automated function calling with a non-streaming prompt ==========\n",
      "The current time in US/Central timezone is 6:47 PM. The current weather in Boston is 61°F and rainy.\n",
      "\n",
      "Now, let's convert the current time from US/Central to US/Eastern timezone. The time difference between Central Time (CT) and Eastern Time (ET) is +1 hour. Thus, the time in Boston would be 7:47 PM.\n",
      "\n",
      "Given the time and weather conditions:\n",
      "- At 7:47 PM, it would be considered after sunset, so the sky is likely to be dark.\n",
      "- The current temperature is 61°F. \n",
      "\n",
      "Therefore, the sky in Boston is most likely dark due to it being evening and rainy. The temperature is 61°F.\n"
     ]
    }
   ],
   "source": [
    "#async def main():\n",
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"function_calling\"\n",
    "\n",
    "# LLM\n",
    "ai_service = AzureChatCompletion(\n",
    "    service_id=service_id,api_key=aoai_api_key, endpoint=aoai_endpoint, api_version=aoai_api_version,deployment_name=deployment_name\n",
    ")\n",
    "\n",
    "kernel.add_service(ai_service)\n",
    "kernel.add_plugin(TimePlugin(), plugin_name=\"time\")\n",
    "kernel.add_plugin(WeatherPlugin(), plugin_name=\"weather\")\n",
    "\n",
    "# automated function calling with a non-streaming prompt\n",
    "print(\"========== Use automated function calling with a non-streaming prompt ==========\")\n",
    "settings: OpenAIChatPromptExecutionSettings = kernel.get_prompt_execution_settings_from_service_id(\n",
    "    service_id=service_id\n",
    ")\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto(filters={\"included_plugins\": [\"weather\", \"time\"]})\n",
    "\n",
    "print(\n",
    "    await kernel.invoke_prompt(        \n",
    "        prompt=\"\"\"Given the current time of day and weather, what is the likely color of the sky in Boston? How much is temperature there?\n",
    "        Make sure you convert current time from US/Central timezone to different timezone based on city name provided.\n",
    "        \"\"\",\n",
    "        settings=settings,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Restaurant menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sample plugin for the sample\n",
    "class MenuPlugin:\n",
    "    \"\"\"A sample Menu Plugin used for the concept sample.\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides a list of specials from the menu.\")\n",
    "    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n",
    "        return \"\"\"\n",
    "        Special Soup: Broccoli cheddar\n",
    "        Special Salad: Cobb Salad\n",
    "        Special Drink: Chai Tea\n",
    "        \"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides the price of the requested menu item.\")\n",
    "    def get_item_price(\n",
    "        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n",
    "    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n",
    "        return \"$9.99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()\n",
    "\n",
    "# Add the AzureChatCompletion AI Service to the Kernel\n",
    "service_id = \"agent\"    \n",
    "\n",
    "# Please make sure your AzureOpenAI Deployment allows for function calling\n",
    "ai_service = AzureChatCompletion(\n",
    "    service_id=service_id,api_key=aoai_api_key, endpoint=aoai_endpoint, api_version=aoai_api_version,deployment_name=deployment_name\n",
    ")    \n",
    "kernel.add_service(ai_service)\n",
    "\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=service_id)\n",
    "# Configure the function choice behavior to auto invoke kernel functions\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Add the MenuPlugin to the Kernel\n",
    "kernel.add_plugin(MenuPlugin(), plugin_name=\"menu\")\n",
    "\n",
    "# Create the agent\n",
    "agent = ChatCompletionAgent(\n",
    "    service_id=\"agent\",\n",
    "    kernel=kernel,\n",
    "    name=\"SampleAssistantAgent\",\n",
    "    instructions=f\"\"\"\n",
    "        You are an agent designed to help with the restaurant menu order.\n",
    "        \"\"\",\n",
    "    execution_settings=settings\n",
    "    )\n",
    "\n",
    "history = ChatHistory()\n",
    "is_complete: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The special menu today includes:\n",
      "- **Special Soup**: Clam Chowder\n",
      "- **Special Salad**: Cobb Salad\n",
      "- **Special Drink**: Chai Tea\n"
     ]
    }
   ],
   "source": [
    "user_input = \"what is the special menu today?\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "async for response in agent.invoke(history=history):\n",
    "            print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The special menu items for today and their prices are:\n",
      "\n",
      "- **Special Soup: Clam Chowder** - $9.99\n",
      "- **Special Salad: Cobb Salad** - $9.99\n",
      "- **Special Drink: Chai Tea** - $9.99\n"
     ]
    }
   ],
   "source": [
    "user_input = \"can you share price for the menu?\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "async for response in agent.invoke(history=history):\n",
    "            print(f\"{response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
